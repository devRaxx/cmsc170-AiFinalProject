{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-10T08:44:52.547676400Z",
     "start_time": "2024-12-10T08:44:46.758109900Z"
    }
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import Label, Button\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "preprocessor_config.json:   0%|          | 0.00/228 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c799005e007748019918f0639b33fa05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\casta\\.cache\\huggingface\\hub\\models--yangy50--garbage-classification. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/883 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37875d936091469787e3527f07815bb7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/343M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43c19b8139cc4e159197d1b990196ce1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"yangy50/garbage-classification\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"yangy50/garbage-classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T08:45:22.993428300Z",
     "start_time": "2024-12-10T08:45:00.738740200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def classify_frame(frame):\n",
    "    # Convert the frame from BGR (OpenCV format) to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # Convert the RGB frame to a PIL image\n",
    "    pil_image = Image.fromarray(rgb_frame)\n",
    "    # Preprocess the image\n",
    "    inputs = processor(images=pil_image, return_tensors=\"pt\")\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Get predicted label\n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax(-1).item()\n",
    "    # Map the predicted index to the corresponding label using model.config.id2label\n",
    "    predicted_label = model.config.id2label[predicted_class_idx]\n",
    "    return predicted_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T09:05:25.014093600Z",
     "start_time": "2024-12-10T09:05:25.009084200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<__main__.GarbageClassifierApp at 0x22878f49510>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<__main__.GarbageClassifierApp at 0x228775b2610>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<__main__.GarbageClassifierApp at 0x22878f576d0>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GarbageClassifierApp:\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "\n",
    "        # Default video source\n",
    "        self.video_source = 0\n",
    "\n",
    "        # Dropdown menu to select camera\n",
    "        self.camera_label = tk.Label(window, text=\"Select Camera:\")\n",
    "        self.camera_label.pack(anchor=tk.W)\n",
    "        self.camera_var = tk.IntVar(value=self.video_source)  # Variable to hold the selected camera index\n",
    "        self.camera_menu = tk.OptionMenu(window, self.camera_var, *[i for i in range(5)], command=self.change_camera)\n",
    "        self.camera_menu.pack(anchor=tk.W)\n",
    "\n",
    "        # Open the video source\n",
    "        self.vid = cv2.VideoCapture(self.video_source)\n",
    "        if not self.vid.isOpened():\n",
    "            raise ValueError(\"Unable to open video source\", self.video_source)\n",
    "\n",
    "        # Create a canvas to display the video frames\n",
    "        self.canvas = tk.Canvas(window, width=self.vid.get(cv2.CAP_PROP_FRAME_WIDTH),\n",
    "                                height=self.vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.canvas.pack()\n",
    "\n",
    "        # Button to capture and classify the current frame\n",
    "        self.btn_classify = Button(window, text=\"Classify\", width=50, command=self.classify_current_frame)\n",
    "        self.btn_classify.pack(anchor=tk.CENTER, expand=True)\n",
    "\n",
    "        # Label to display the classification result\n",
    "        self.label_result = Label(window, text=\"Classification Result: \")\n",
    "        self.label_result.pack(anchor=tk.CENTER, expand=True)\n",
    "\n",
    "        # Start the video loop\n",
    "        self.delay = 15\n",
    "        self.update()\n",
    "\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def change_camera(self, camera_index):\n",
    "        # Release the current video source\n",
    "        if self.vid.isOpened():\n",
    "            self.vid.release()\n",
    "\n",
    "        # Set the new video source\n",
    "        self.video_source = int(camera_index)\n",
    "        self.vid = cv2.VideoCapture(self.video_source)\n",
    "        if not self.vid.isOpened():\n",
    "            self.label_result.config(text=f\"Unable to open camera {self.video_source}\")\n",
    "        else:\n",
    "            self.label_result.config(text=f\"Camera {self.video_source} selected\")\n",
    "\n",
    "    def update(self):\n",
    "        # Get a frame from the video source\n",
    "        ret, frame = self.vid.read()\n",
    "        if ret:\n",
    "            # Define the square's size and position\n",
    "            height, width, _ = frame.shape\n",
    "            square_size = 200  # Size of the square (length of a side)\n",
    "            top_left = (width // 2 - square_size // 2, height // 2 - square_size // 2)\n",
    "            bottom_right = (width // 2 + square_size // 2, height // 2 + square_size // 2)\n",
    "\n",
    "            # Draw a green square on the frame\n",
    "            color = (0, 255, 0)  # Green color in BGR\n",
    "            thickness = 2  # Thickness of the rectangle border\n",
    "            cv2.rectangle(frame, top_left, bottom_right, color, thickness)\n",
    "\n",
    "            # Convert the frame to RGB format\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Convert the image to PIL format\n",
    "            pil_image = Image.fromarray(rgb_frame)\n",
    "            # Convert the PIL image to ImageTk format\n",
    "            imgtk = ImageTk.PhotoImage(image=pil_image)\n",
    "            # Display the image on the canvas\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=imgtk)\n",
    "            self.photo = imgtk\n",
    "        # Repeat after a delay\n",
    "        self.window.after(self.delay, self.update)\n",
    "\n",
    "    def classify_current_frame(self):\n",
    "        # Get the current frame\n",
    "        ret, frame = self.vid.read()\n",
    "        if ret:\n",
    "            # Get the region of interest (ROI) inside the square\n",
    "            height, width, _ = frame.shape\n",
    "            square_size = 1000\n",
    "            top_left = (width // 2 - square_size // 2, height // 2 - square_size // 2)\n",
    "            bottom_right = (width // 2 + square_size // 2, height // 2 + square_size // 2)\n",
    "\n",
    "            # Crop the region inside the square\n",
    "            roi = frame[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "            # Classify the frame\n",
    "            label = classify_frame(roi)\n",
    "            # Display the result\n",
    "            self.label_result.config(text=f\"Classification Result: {label}\")\n",
    "            if label in [\"cardboard\",\"paper\",\"trash\"]:\n",
    "                self.label_result.config(text=\"Biodegradable\")\n",
    "            else:\n",
    "                self.label_result.config(text=\"Non-Biodegradable\")\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.vid.isOpened():\n",
    "            self.vid.release()\n",
    "\n",
    "\n",
    "# Create a window and pass it to the Application object\n",
    "GarbageClassifierApp(tk.Tk(), \"Garbage Classifier\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T09:08:41.894205300Z",
     "start_time": "2024-12-10T09:08:33.770459800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
